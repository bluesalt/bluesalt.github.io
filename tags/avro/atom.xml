<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: avro | Jeff Li]]></title>
  <link href="http://bluesalt.github.io/tags/avro/atom.xml" rel="self"/>
  <link href="http://bluesalt.github.io/"/>
  <updated>2014-04-07T17:24:23+08:00</updated>
  <id>http://bluesalt.github.io/</id>
  <author>
    <name><![CDATA[Jeff Li]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Avro Cookbook : Part II]]></title>
    <link href="http://bluesalt.github.io/blog/2014/04/05/avro-cookbook-part-ii/"/>
    <updated>2014-04-05T18:31:35+08:00</updated>
    <id>http://bluesalt.github.io/blog/2014/04/05/avro-cookbook-part-ii</id>
    <content type="html"><![CDATA[<h2>Recipe 5: Serialize data without Code Generation</h2>

<p>In formal recipes, before using Avro to serialize/deserialize data, schema files have to be defined to be leveraged by Avro code generation facility to generate the Java classes. This is also recommended when using Avro in Java. However, it is not required. Actually, you can parse the schema on the fly without code generation.</p>

<h3>Parse Schema from String</h3>

<p>The schema looks like this:
<code>json
{
 &quot;namespace&quot;: &quot;me.jeffli.avrosamples.model&quot;,
 &quot;type&quot;: &quot;record&quot;,
 &quot;name&quot;: &quot;LogEntry2&quot;,
 &quot;fields&quot;: [
     {&quot;name&quot;: &quot;name&quot;, &quot;type&quot;: &quot;string&quot;},
     {&quot;name&quot;: &quot;resource&quot;,  &quot;type&quot;: [&quot;string&quot;, &quot;null&quot;]},
     {&quot;name&quot;: &quot;ip&quot;, &quot;type&quot;: [&quot;string&quot;, &quot;null&quot;]}
 ]
}
</code>
Define the schema as a Java String:
<pre>
String schemaDesc = &quot;{\n&quot; +
           &quot; \&quot;namespace\&quot;: \&quot;me.jeffli.avrosamples.model\&quot;,\n&quot; +
           &quot; \&quot;type\&quot;: \&quot;record\&quot;,\n&quot; +
           &quot; \&quot;name\&quot;: \&quot;LogEntry2\&quot;,\n&quot; +
           &quot; \&quot;fields\&quot;: [\n&quot; +
           &quot;     {\&quot;name\&quot;: \&quot;name\&quot;, \&quot;type\&quot;: \&quot;string\&quot;},\n&quot; +
           &quot;     {\&quot;name\&quot;: \&quot;resource\&quot;,  \&quot;type\&quot;: [\&quot;string\&quot;, \&quot;null\&quot;]},\n&quot; +
           &quot;     {\&quot;name\&quot;: \&quot;ip\&quot;, \&quot;type\&quot;: [\&quot;string\&quot;, \&quot;null\&quot;]}\n&quot; +
           &quot; ]\n&quot; +
           &quot;}&quot;;
</pre></p>

<p>Then the code to serialize the data would be this:
```java
@Test
public void testSerializeOnTheFly() throws IOException {
   Schema schema = new Schema.Parser().parse(schemaDesc);
   GenericRecord entry1 = new GenericData.Record(schema);
   entry1.put(&quot;name&quot;, &quot;Jeffrey&quot;);
   entry1.put(&quot;resource&quot;, &quot;README&quot;);
   entry1.put(&quot;ip&quot;, &quot;192.168.2.1&quot;);</p>

<p>GenericRecord entry2 = new GenericData.Record(schema);
   entry2.put(&quot;name&quot;, &quot;Johnson&quot;);
   entry2.put(&quot;resource&quot;, &quot;readme.markdown&quot;);
   entry2.put(&quot;ip&quot;, &quot;192.168.2.2&quot;);</p>

<p>DatumWriter<GenericRecord> datumWriter = new GenericDatumWriter&lt;&gt;(schema);
   DataFileWriter<GenericRecord> dataFileWriter = new DataFileWriter&lt;&gt;(datumWriter);
   File file = new File(&quot;/tmp/log2&quot;);
   dataFileWriter.create(schema, file);</p>

<p>dataFileWriter.append(entry1);
   dataFileWriter.append(entry2);
   dataFileWriter.close();
}
```
From the example, we can see that we don&#39;t need to define any external schema file and no external Java classed are generated.</p>

<h3>Parse Schema from Disk File</h3>

<p>In the above example, we parse the schema from String. Since the schema is defined with JSON language, it is cumbersome to define the schema as a Java String. Fortunately Avro Schema.Paser also provides other API to parse the schema from disk file or existing Java class :</p>
<div class="highlight"><pre><code class="java"><span class="n">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Schema</span><span class="o">.</span><span class="na">Parser</span><span class="o">().</span><span class="na">parse</span><span class="o">(</span><span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="s">&quot;src/test/resources/LogEntry2.avsc&quot;</span><span class="o">));</span>
</code></pre></div>
<h3>Parse Schema from Existing Java Class</h3>

<p>Per the JSON Schema definition, a equivalent Java class would look like this:
```java
public class LogEntry3 {
   private String name;
   private String resource;
   private String ip;</p>

<p>public LogEntry3(String name, String resource, String ip) {
      this.name = name;
      this.resource = resource;
      this.ip = ip;
   }</p>

<p>public String getName() {
      return name;
   }</p>

<p>public void setName(String name) {
      this.name = name;
   }</p>

<p>public String getResource() {
      return resource;
   }</p>

<p>public void setResource(String resource) {
      this.resource = resource;
   }</p>

<p>public String getIp() {
      return ip;
   }</p>

<p>public void setIp(String ip) {
      this.ip = ip;
   }
}
```</p>

<p>Then the Schema can be fetched easily:
<code>java
Schema schema = ReflectData.get().getSchema(LogEntry3.class);
</code></p>

<h2>Recipe 6: Deserialize data without Code Generation</h2>

<p>Deserializing data without code generation is pretty easy. The only difference with Recipe 4 is how it get the <strong>schema</strong>. Thus the ways to fetch schemas in Recipe 5 are also applicable in this recipe. Here is only the example to load schema from disk file. I am pretty sure that you can finish the rest code.</p>
<div class="highlight"><pre><code class="java"><span class="nd">@Test</span><span class="o">(</span><span class="n">dependsOnMethods</span> <span class="o">=</span> <span class="s">&quot;testSerializeOnTheFly&quot;</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">testDeserializeOnTheFly</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
   <span class="n">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Schema</span><span class="o">.</span><span class="na">Parser</span><span class="o">().</span><span class="na">parse</span><span class="o">(</span><span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="s">&quot;src/test/resources/LogEntry2.avsc&quot;</span><span class="o">));</span>
   <span class="n">DatumReader</span><span class="o">&lt;</span><span class="n">GenericRecord</span><span class="o">&gt;</span> <span class="n">datumReader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">GenericDatumReader</span><span class="o">&lt;&gt;(</span><span class="n">schema</span><span class="o">);</span>
   <span class="n">File</span> <span class="n">file</span> <span class="o">=</span> <span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="s">&quot;/tmp/log2&quot;</span><span class="o">);</span>
   <span class="n">DataFileReader</span><span class="o">&lt;</span><span class="n">GenericRecord</span><span class="o">&gt;</span> <span class="n">dataFileReader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DataFileReader</span><span class="o">&lt;&gt;(</span><span class="n">file</span><span class="o">,</span> <span class="n">datumReader</span><span class="o">);</span>
   <span class="n">GenericRecord</span> <span class="n">entry</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
   <span class="k">while</span> <span class="o">(</span><span class="n">dataFileReader</span><span class="o">.</span><span class="na">hasNext</span><span class="o">())</span> <span class="o">{</span>
      <span class="n">entry</span> <span class="o">=</span> <span class="n">dataFileReader</span><span class="o">.</span><span class="na">next</span><span class="o">(</span><span class="n">entry</span><span class="o">);</span>
      <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">entry</span><span class="o">);</span>
   <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Avro Cookbook : Part I]]></title>
    <link href="http://bluesalt.github.io/blog/2014/02/06/avro-cookbook-part-i/"/>
    <updated>2014-02-06T15:49:00+08:00</updated>
    <id>http://bluesalt.github.io/blog/2014/02/06/avro-cookbook-part-i</id>
    <content type="html"><![CDATA[<p>Avro is a data serialization framework. It is an Apache project led by Doug Cutting who is also the author of several other open source projects such as Hadoop, Lucene. Recently I need to leverage Avro to serialize/deserialize some data, however, I found its document is too poor, at least too poor for newbies like me who don&#39;t have much experience on data exchange format frameworks. </p>

<p>In fact, it is very easy to understand what Avro can do. It helps to convert Java objects into bytes and vice versa. The key information the framework needs to know is the format of the date, namely &#39;Schema&#39; in Avro. In this article, I won&#39;t spend any time on explaining what Avro is. </p>

<h2>Recipe 1: Create a Maven Avro Project</h2>

<p>Intellij IDEA is my favorite Java IDE. The free Community edition has less features than the commercial Ultimate edition, however, great experience may be gained when the free community IDEA works with Maven. They complete each other. So the examples in this article will use Maven and Intellij IDEA as the IDE. Besides, <strong>TestNG</strong> instead of JUnit will be used as the test framework.</p>

<h3>Initialize the project structure</h3>

<ul>
<li>Create an project with quickstart archetype:
<code>
mvn archetype:generate -DgroupId=me.jeffli -DartifactId=avrosamples -Dversion=0.01 -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false
</code></li>
</ul>

<h3>Tweak the pom.xml</h3>

<ul>
<li><p>Add Avro dependency:
<code>xml
&lt;dependency&gt;
&lt;groupId&gt;org.apache.avro&lt;/groupId&gt;
&lt;artifactId&gt;avro&lt;/artifactId&gt;
&lt;version&gt;1.7.5&lt;/version&gt;
&lt;/dependency&gt;
</code></p></li>
<li><p>Use Avro Maven plugin
<code>xml
&lt;plugin&gt;
&lt;groupId&gt;org.apache.avro&lt;/groupId&gt;
&lt;artifactId&gt;avro-maven-plugin&lt;/artifactId&gt;
&lt;version&gt;1.7.5&lt;/version&gt;
&lt;executions&gt;
  &lt;execution&gt;
     &lt;phase&gt;generate-sources&lt;/phase&gt;
     &lt;goals&gt;
        &lt;goal&gt;schema&lt;/goal&gt;
     &lt;/goals&gt;
     &lt;configuration&gt;
        &lt;!-- make sure the directory is created --&gt;
        &lt;sourceDirectory&gt;${project.basedir}/src/main/avro/&lt;/sourceDirectory&gt;
        &lt;outputDirectory&gt;${project.basedir}/src/main/java/&lt;/outputDirectory&gt;
     &lt;/configuration&gt;
  &lt;/execution&gt;
&lt;/executions&gt;
&lt;/plugin&gt;
</code></p></li>
</ul>

<p>It should be noted that the directory <code>${project.basedir}/src/main/avro/</code> must be created even it is empty at first. It is used to place the Avro schema files. The whole pom.xml has been posted to <a href="https://gist.github.com/bluesalt/9807306">github gist</a>.</p>

<h3>Import the project into Intellij IDEA</h3>

<p>IDEA provides full support to Maven, so it is very easy to import the Maven project as a IDEA project. Click &quot;Import Project&quot; in the &#39;Quick Start&#39; panel. I suggest enable the Maven Auto-Import feature of IDEA before completing the importing process.</p>

<h2>Recipe 2: Define a Schema</h2>

<p>Assume that you want to log every access of your server, to make it simple, we only define 3 attributes in a log entry, namely the username, resource and ip. So the schema can be defined as :
<code>json
{
 &quot;namespace&quot;: &quot;me.jeffli.avrosamples.model&quot;,
 &quot;type&quot;: &quot;record&quot;,
 &quot;name&quot;: &quot;LogEntry&quot;,
 &quot;fields&quot;: [
     {&quot;name&quot;: &quot;name&quot;, &quot;type&quot;: &quot;string&quot;},
     {&quot;name&quot;: &quot;resource&quot;,  &quot;type&quot;: [&quot;string&quot;, &quot;null&quot;]},
     {&quot;name&quot;: &quot;ip&quot;, &quot;type&quot;: [&quot;string&quot;, &quot;null&quot;]}
 ]
}
</code></p>

<p>Save the content as <code>${project.basedir}/src/main/avro/LogEntry.avsc</code>. After running <code>mvn compile</code>, a Java class <code>me.jeffli.avrosamples.model.LogEntry</code> will be generated automatically thank to the Avro Maven plugin.  </p>

<h2>Recipe 3: Serialize the Log Data to Disk File</h2>

<p>Assume we want to store the log data to a disk file <code>/tmp/log</code>. The code snippet would be like this:
```java
@Test
public void testSerializeLogEntries() throws IOException {
   LogEntry entry1 = new LogEntry();
   entry1.setName(&quot;Jeff&quot;);
   entry1.setResource(&quot;readme.txt&quot;);
   entry1.setIp(&quot;192.168.1.1&quot;);</p>

<p>LogEntry entry2 = new LogEntry();
   entry2.setName(&quot;John&quot;);
   entry2.setResource(&quot;readme.md&quot;);
   entry2.setIp(&quot;192.168.1.2&quot;);</p>

<p>DatumWriter<LogEntry> logEntryDatumWriter = new SpecificDatumWriter&lt;&gt;(LogEntry.class);
   DataFileWriter<LogEntry> dataFileWriter = new DataFileWriter&lt;&gt;(logEntryDatumWriter);
   File file = new File(&quot;/tmp/log&quot;);
   dataFileWriter.create(entry1.getSchema(), file);</p>

<p>dataFileWriter.append(entry1);
   dataFileWriter.append(entry2);</p>

<p>dataFileWriter.close();
}
```  </p>

<h2>Recipe 4: Deserialize the Log Data from Disk File</h2>

<p>Assume you need to parse the log data from disk files <code>/tmp/log</code>. Then the code snippet would be:
<code>java
@Test (dependsOnMethods = &quot;testSerializeLogEntries&quot;)
public void testDeSerializeLogEntries() throws IOException {
   DatumReader&lt;LogEntry&gt; logEntryDatumReader = new SpecificDatumReader&lt;&gt;(LogEntry.class);
   File file = new File(&quot;/tmp/log&quot;);
   DataFileReader&lt;LogEntry&gt; dataFileReader = new DataFileReader&lt;&gt;(file, logEntryDatumReader);
   LogEntry entry = null;
   while (dataFileReader.hasNext()) {
      entry = dataFileReader.next(entry);
      System.out.println(entry);
   }
}
</code>   </p>
]]></content>
  </entry>
  
</feed>
